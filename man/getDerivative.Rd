% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/getDerivative.R
\name{getDerivative}
\alias{getDerivative}
\title{Combined Derivative Computation of \eqn{\beta}'s.}
\usage{
getDerivative(formula, n.vars, family, learningrate, dif, datasources)
}
\arguments{
\item{formula}{a character that can be coerced to an object of class \code{\link[stats]{formula}}. It is a symbolic
description of the model to be fitted.}

\item{n.vars}{a numeric, the number of study variables.}

\item{family}{a string character with the name of the error distribution and link function to be used in the analysis.
If \code{family} is set to 'binomial' it defines the link function as logit, and likelihood as binomial.
If \code{family} is set to 'poisson' it defines the link function as log, and likelihood as poisson.}

\item{learningrate}{a numeric, controls how much we are adjusting the regression model.}

\item{dif}{a numeric, controls the learning convergence.}

\item{datasources}{a list of opal object(s) obtained after login in to opal servers;
these objects hold also the data assign to R, as \code{data frame}, from opal datasources.}
}
\value{
Returns a list with the following components:
\item{call}{the model formula.}
\item{coefficients}{a vector of linear regression coefficients.}
\item{xtxw}{a data matrix, the \emph{Hessian} matrix.}
\item{xtyp}{a data matrix, that integrates the computation of derivatives.}
}
\description{
Computes the \eqn{\beta} for each interation.
}
\details{
The straightforward way to compute the \eqn{b} coefficients is the Newton's method.
Suppose that there is a valued function \eqn{y = f(b)}.
The problem is find the value \eqn{b[k]} such that \eqn{f(b[k]) = 0}.
Starting with an initial value for \eqn{b[0]}, the Taylor expansion of \emph{f} can be done around \eqn{b[0]}:
\deqn{f(b[0] + \beta) =~ f(b[0]) + f'(b[0]) * \beta}
The \emph{f'} is a matrix, a Jacobean if first derivative of \emph{f} with respect to \emph{b}.
In this equation, setting the left side as zero, the \eqn{\beta} can be solved as
\deqn{\beta[0] = -[f'(\beta[0])]^(-1) * f(b[0])}
So the update of estimated for \emph{b} is:
\deqn{b[1] = b[0] + \beta[0]}
and iterate until convergence.
}
\section{Dependencies}{

\code{\link{getDerivativeDS}}
}

\seealso{
Other regressions: \code{\link{ds.linear}},
  \code{\link{ds.logistic}}, \code{\link{ds.poisson}}
}
\author{
Paula R. Silva
}
\concept{regressions}
